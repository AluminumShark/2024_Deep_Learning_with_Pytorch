{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUAa0gk1Aq7+zCuWPpsZ8Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AluminumShark/2023_Labor_Economics/blob/main/01_MINIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f204-iC5WdG2",
        "outputId": "e6e47dea-a4e2-4b99-facc-d6495f5a8383"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.3)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from keras.datasets import mnist"
      ],
      "metadata": {
        "id": "ybbCxM6ychq9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "\n",
        "batch_size = 320\n",
        "epochs = 1024\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print(\"CUDA is available. Using GPU.\")\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print(\"CUDA is not available. Using CPU.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sebMFtBOiQev",
        "outputId": "13f20a2f-4abd-4918-e8ab-2da1aab0a30f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is not available. Using CPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Up NeuralNetWork\n",
        "\n",
        "class NeuralNetWork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetWork, self).__init__()\n",
        "\n",
        "    self.flatten = nn.Flatten()\n",
        "\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        torch.nn.Linear(28*28, 512),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(512, 512),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(512, 10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.linear_relu_stack(x)\n",
        "    return logits\n",
        "\n",
        "model = NeuralNetWork().to(device)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 2e-5)"
      ],
      "metadata": {
        "id": "zF9nbXFFik2N"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Data\n",
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
        "\n",
        "train_num = len(train_X) // batch_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PTdTQHKpCHq",
        "outputId": "792260d2-cdd0-422f-a5a6-7652469b3f1a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start Training\n",
        "\n",
        "for epoch in range(20):\n",
        "  train_loss = 0\n",
        "  for i in range(train_num):\n",
        "     start = i * batch_size\n",
        "     end = (i+1) * batch_size\n",
        "\n",
        "     train_X_batch = torch.tensor(train_X[start:end], dtype=torch.float32).to(device)\n",
        "     train_y_batch = torch.tensor(train_y[start:end]).to(device)\n",
        "\n",
        "     pred = model(train_X_batch)\n",
        "     loss = loss_function(pred, train_y_batch)\n",
        "\n",
        "     optimizer.zero_grad()\n",
        "     loss.backward()\n",
        "     optimizer.step()\n",
        "\n",
        "     train_loss += loss.item()\n",
        "\n",
        "  train_loss /= train_num\n",
        "  accuarcy = (pred.argmax(1) == train_y_batch).type(torch.float32).sum().item() / batch_size\n",
        "\n",
        "  print(\"Train Loss : \", round(train_loss, 2), \"Accuarcy : \", round(accuarcy, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOilRaZnqSiL",
        "outputId": "7fdbed64-dff6-4624-a59f-e0d3c0186197"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss :  0.49 Accuarcy :  0.94\n",
            "Train Loss :  0.33 Accuarcy :  0.95\n",
            "Train Loss :  0.25 Accuarcy :  0.95\n",
            "Train Loss :  0.2 Accuarcy :  0.96\n",
            "Train Loss :  0.16 Accuarcy :  0.97\n",
            "Train Loss :  0.14 Accuarcy :  0.97\n",
            "Train Loss :  0.11 Accuarcy :  0.97\n",
            "Train Loss :  0.1 Accuarcy :  0.97\n",
            "Train Loss :  0.08 Accuarcy :  0.97\n",
            "Train Loss :  0.07 Accuarcy :  0.98\n",
            "Train Loss :  0.06 Accuarcy :  0.98\n",
            "Train Loss :  0.05 Accuarcy :  0.98\n",
            "Train Loss :  0.04 Accuarcy :  0.98\n",
            "Train Loss :  0.04 Accuarcy :  0.98\n",
            "Train Loss :  0.03 Accuarcy :  0.99\n",
            "Train Loss :  0.03 Accuarcy :  0.99\n",
            "Train Loss :  0.02 Accuarcy :  0.99\n",
            "Train Loss :  0.02 Accuarcy :  1.0\n",
            "Train Loss :  0.02 Accuarcy :  1.0\n",
            "Train Loss :  0.02 Accuarcy :  1.0\n"
          ]
        }
      ]
    }
  ]
}